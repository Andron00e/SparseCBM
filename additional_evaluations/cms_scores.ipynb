{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5da3a57-c943-40b4-a4c1-e5b2498807a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8f7f62e-37c5-45eb-9c67-74ad2bf06404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "573b7e29-ac76-401a-8acb-b63885a8f179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "def set_device(device_no: int):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "        print(\"We will use the GPU:\", torch.cuda.get_device_name(device_no))\n",
    "    else:\n",
    "        print(\"No GPU available, using the CPU instead.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    return device\n",
    "\n",
    "device = set_device(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98bbd5e-9867-4d84-a672-e172d01a81a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a4a9cff8-9ecc-4377-aa7a-573800b3bcc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from configs import *\n",
    "import clip\n",
    "import open_clip\n",
    "from open_clip import tokenizer\n",
    "from PIL import Image\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.io import output_notebook\n",
    "from sklearn.decomposition import PCA\n",
    "import bokeh.models as bm, bokeh.plotting as pl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def get_image_features(path_to_im: str, classes: dict, N: int, model_name=\"ViT-B-16\", model_author=\"openai\",\n",
    "                       device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path_to_im: path to the directory with images data\n",
    "        classes: dict of class idx, class label pairs\n",
    "        N: how many images of every class to take\n",
    "        model_name: name of CLIP model's Image Encoder\n",
    "        model_author: pretrained name of CLIP model from open_clip\n",
    "        device: device\n",
    "    Return: torch.Tensor of encoded by CLIP model images\n",
    "    \"\"\"\n",
    "    image_dirs = [path_to_im + \"/{}/\".format(cls) for cls in classes.values()]\n",
    "\n",
    "    selected_images = []\n",
    "    for direc in image_dirs:\n",
    "        filenames = os.listdir(direc)\n",
    "        upd_filenames = [direc + f for f in filenames]\n",
    "        selected_images.append(sorted(upd_filenames[:N]))\n",
    "\n",
    "    selected_images = [item for sublist in selected_images for item in sublist]\n",
    "\n",
    "    image_inputs = []\n",
    "    clip_model, _, preprocess = open_clip.create_model_and_transforms(model_name, pretrained=model_author,\n",
    "                                                                      device=device)\n",
    "    for name in tqdm(selected_images):\n",
    "        im = Image.open(name)\n",
    "        im_input = preprocess(im).unsqueeze(0).to(device)\n",
    "        image_inputs.append(im_input)\n",
    "\n",
    "    image_inputs = torch.stack(image_inputs, dim=0)\n",
    "\n",
    "    image_encodings = []\n",
    "    with torch.no_grad():\n",
    "        for image in tqdm(image_inputs):\n",
    "            image_feature = clip_model.encode_image(image)\n",
    "            image_encodings.append(image_feature)\n",
    "\n",
    "    image_features = torch.stack(image_encodings, dim=0)\n",
    "\n",
    "    return image_features\n",
    "\n",
    "def remove_prefixes(strings):\n",
    "    prefixes = ['a', 'an', 'the']\n",
    "    result = []\n",
    "    for string in strings:\n",
    "        words = string.split()\n",
    "        if words[0].lower() in prefixes:\n",
    "            result.append(' '.join(words[1:]))\n",
    "        else:\n",
    "            result.append(string)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_text_features(path_to_text: str, model_name=\"ViT-B-16\", model_author=\"openai\", device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path_to_text: path to the directory with texts data\n",
    "        model_name: name of CLIP model's Image Encoder\n",
    "        model_author: pretrained name of CLIP model from open_clip\n",
    "        device: device\n",
    "    Return: torch.Tensor of encoded by CLIP model texts\n",
    "    \"\"\"\n",
    "    with open(path_to_text, \"r\") as f:\n",
    "        texts = f.read().lower().split(\"\\n\")\n",
    "        texts = remove_prefixes(texts)\n",
    "\n",
    "    text_encodings = []\n",
    "    clip_model, _, preprocess = open_clip.create_model_and_transforms(model_name, pretrained=model_author,\n",
    "                                                                      device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for c in tqdm(texts):\n",
    "            text_input = clip.tokenize(c).to(device)\n",
    "            text_feature = clip_model.encode_text(text_input)\n",
    "            text_encodings.append(text_feature)\n",
    "\n",
    "    text_features = torch.stack(text_encodings, dim=0)\n",
    "\n",
    "    return text_features\n",
    "def similarity(a: torch.Tensor, b: torch.Tensor):\n",
    "    nom = a @ b.T\n",
    "    denom = a.norm(dim=-1) * b.norm(dim=-1)\n",
    "    return nom / denom\n",
    "\n",
    "def cubed_similarity(a: torch.Tensor, b: torch.Tensor):\n",
    "    nom = a**3 @ (b**3).T\n",
    "    denom = (a**3).norm(dim=-1) * (b**3).norm(dim=-1)\n",
    "    return nom / denom\n",
    "\n",
    "def get_dot_prods_matrix(image_features: torch.Tensor, text_features: torch.Tensor, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image_features: tensor of shape [num_images, dim]\n",
    "        text_features: tensor of shape [num_texts, dim]\n",
    "        eps: to avoid division by zero\n",
    "    Return: images-texts matrix with normalized rows (sum of each row == 1.)\n",
    "    \"\"\"\n",
    "    image_features = image_features.squeeze(dim=1)\n",
    "    text_features = text_features.squeeze(dim=1)\n",
    "    image_norms = image_features.norm(dim=-1, keepdim=True) ** 2\n",
    "    text_norms = text_features.norm(dim=-1, keepdim=True) ** 2\n",
    "    matrix = image_features @ text_features.T\n",
    "    matrix /= torch.sqrt(image_norms @ text_norms.T)\n",
    "    row_sum = torch.sum(matrix, dim=1, keepdim=True)\n",
    "    matrix /= row_sum + eps\n",
    "    return matrix\n",
    "\n",
    "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
    "                 width=600, height=400, show=True, **kwargs):\n",
    "    \"\"\" draws an interactive plot for data points with auxiliary info on hover \"\"\"\n",
    "    if isinstance(color, str): color = [color] * len(x)\n",
    "    data_source = bm.ColumnDataSource({'x': x, 'y': y, 'color': color, **kwargs})\n",
    "\n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
    "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
    "\n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
    "    if show: pl.show(fig)\n",
    "    return fig\n",
    "\n",
    "def generate_slices_for_classes(classes: dict, V_matrix: torch.Tensor):\n",
    "    \"\"\"\n",
    "    classes: dict of cls_idx: class_name\n",
    "    V_matrix: image-concepts matrix\n",
    "    return: slices for every class\n",
    "    \"\"\"\n",
    "    slice_size = len(V_matrix) // len(classes)\n",
    "    slices = {}\n",
    "    for i, class_idx in enumerate(classes):\n",
    "        start = i * slice_size\n",
    "        end = (i + 1) * slice_size\n",
    "        slices[classes[class_idx]] = slice(start, end)\n",
    "\n",
    "    return slices\n",
    "\n",
    "def calculate_similarity_score(classes: dict, V_rows: torch.Tensor, T_matrix: torch.Tensor, sim: str=\"sim\"):\n",
    "    \"\"\"\n",
    "    V_rows: a rows of V_matrix for the same class\n",
    "    T_matrix: classes-concepts matrix\n",
    "    return: a dictionary with similarity scores for each class\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "\n",
    "    for v_row in V_rows:\n",
    "        for i in range(len(T_matrix)):\n",
    "            t_row = T_matrix[i]\n",
    "\n",
    "            if sim == \"sim\":\n",
    "                sim = similarity(v_row, t_row)\n",
    "            else:\n",
    "                sim = cubed_similarity(v_row, t_row)\n",
    "\n",
    "            class_name = classes[i]\n",
    "\n",
    "            if class_name in scores:\n",
    "                scores[class_name] += sim.item()\n",
    "            else:\n",
    "                scores[class_name] = sim.item()\n",
    "\n",
    "    return scores\n",
    "\n",
    "def get_scores_dict(classes: dict, V_matrix: torch.Tensor, T_matrix: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        classes: classes dict\n",
    "        V_matrix:\n",
    "        T_matrix:\n",
    "    Return: scores_dict for drawing similarity scores\n",
    "    \"\"\"\n",
    "    scores_dict = {}\n",
    "    slices = generate_slices_for_classes(classes, V_matrix)\n",
    "\n",
    "    for class_name, slice_range in slices.items():\n",
    "        V_rows = V_matrix[slice_range]\n",
    "        scores = calculate_similarity_score(classes, V_rows, T_matrix)\n",
    "        scores_dict[class_name] = scores\n",
    "\n",
    "    return scores_dict\n",
    "\n",
    "def draw_similarity_scores(scores_dict: dict, true_class: str):\n",
    "    \"\"\"\n",
    "    scores_dict: a nested dictionary with similarity scores\n",
    "    true_class: the true image class for which scores should be plotted\n",
    "    \"\"\"\n",
    "\n",
    "    if true_class not in scores_dict:\n",
    "        print(f\"True class '{true_class}' not found in the scores dictionary.\")\n",
    "        return\n",
    "\n",
    "    scores = scores_dict[true_class]\n",
    "    df = pd.DataFrame(list(scores.items()), columns=['Class', 'Total Similarity Score'])\n",
    "\n",
    "    plt.figure(figsize=(6, 3))  # 12 6\n",
    "    sns.scatterplot(data=df, x='Class', y='Total Similarity Score')\n",
    "    plt.title(f\"Similarity Scores for True Class: {true_class}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(\"Classes\")\n",
    "    plt.ylabel(\"Total Similarity Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def calculate_similarity_score_accuracy_for_class(class_name: str, V_matrix: torch.Tensor, T_matrix: torch.Tensor, classes: dict):\n",
    "    \"\"\"\n",
    "    Test the accuracy of the hypothesis\n",
    "    return: accuracy score for the class_name label by similarity method\n",
    "    \"\"\"\n",
    "    slices = generate_slices_for_classes(classes, V_matrix)\n",
    "    slice_range = slices[class_name]\n",
    "    V_rows = V_matrix[slice_range]\n",
    "    sim_matrix = torch.zeros((V_rows.shape[0], T_matrix.shape[0]))\n",
    "    \n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    for i, v_row in enumerate(V_rows):\n",
    "        for j, t_row in enumerate(T_matrix):\n",
    "            sim_matrix[i, j] = similarity(v_row, t_row).item()\n",
    "            \n",
    "    for idx in range(sim_matrix.shape[0]):\n",
    "        pred_idx = torch.argmax(sim_matrix[idx])\n",
    "        \n",
    "        if pred_idx == list(classes.values()).index(class_name):\n",
    "            correct += 1.0\n",
    "        total += 1.0\n",
    "        \n",
    "    return 100 * correct / total\n",
    "    \n",
    "def similarity_score_accuracy(classes: dict, V_matrix: torch.Tensor, T_matrix: torch.Tensor):\n",
    "    mean = np.mean([calculate_similarity_score_accuracy_for_class(class_name, V_matrix, T_matrix, classes) for class_name in classes.values()])\n",
    "    return \"Similarity Score accuracy: {}%\".format(mean)\n",
    "\n",
    "def calculate_max_score_accuracy_for_class(class_name: str, V_matrix: torch.Tensor, T_matrix: torch.Tensor, classes: dict):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        class_name: name of class from classes dict\n",
    "        V_matrix: yeap\n",
    "        T_matrix: yeap\n",
    "        classes: classes dict\n",
    "    Return:\n",
    "    \"\"\"\n",
    "    slices = generate_slices_for_classes(classes, V_matrix)\n",
    "    slice_range = slices[class_name]\n",
    "    V_rows = V_matrix[slice_range]\n",
    "\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for v_row in V_rows:\n",
    "        max_elem_idx = torch.argmax(v_row).item()\n",
    "        t_matrix_column = T_matrix[:, max_elem_idx]\n",
    "        t_max_elem_idx = torch.argmax(t_matrix_column).item()\n",
    "\n",
    "        if classes[t_max_elem_idx] == class_name:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "def max_score_accuracy(classes: dict, V_matrix: torch.Tensor, T_matrix: torch.Tensor):\n",
    "    mean = np.mean([calculate_max_score_accuracy_for_class(class_name, V_matrix, T_matrix, classes) for class_name in classes.values()])\n",
    "    return \"Max Score accuracy: {}%\".format(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c867a6ef-2610-471a-8a0a-2a3ac82d157b",
   "metadata": {},
   "source": [
    "## experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ddf617a-4215-40f1-ac30-9513f669db31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}\n"
     ]
    }
   ],
   "source": [
    "classes = {}\n",
    "\n",
    "with open(\"./datasets/cifar10/labels.txt\", \"r\") as f:\n",
    "    cls_names = f.read().lower().split(\"\\n\")\n",
    "\n",
    "for i, cls_name in enumerate(cls_names):\n",
    "    classes[i] = cls_name\n",
    "\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2c627277-25d2-432f-98b6-dd426a247f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [00:08<00:00, 57.95it/s]\n",
      "100%|████████████████████████████████████████| 500/500 [00:02<00:00, 170.34it/s]\n"
     ]
    }
   ],
   "source": [
    "image_features = get_image_features(\"./datasets/cifar10/train\", classes=classes, N=50, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "92b65a30-35f2-4640-98a7-35eb4061d6bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5051/5051 [00:39<00:00, 127.38it/s]\n",
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 130.23it/s]\n"
     ]
    }
   ],
   "source": [
    "concept_features = get_text_features(\"all_concepts.txt\", device=device)\n",
    "class_features = get_text_features(\"datasets/cifar10/labels.txt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e854aa9b-8819-4a42-97de-7c7c4c218eef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_matrix: torch.Size([500, 5051]) \n",
      "\n",
      "T_matrix: torch.Size([10, 5051])\n"
     ]
    }
   ],
   "source": [
    "V_matrix = get_dot_prods_matrix(image_features, concept_features)\n",
    "T_matrix = get_dot_prods_matrix(class_features, concept_features)\n",
    "\n",
    "print('V_matrix:', V_matrix.shape, \"\\n\")\n",
    "print('T_matrix:', T_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "46086825-fbcc-4b18-9516-c516f2475bae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score accuracy: 61.0% \n",
      "\n",
      "Max Score accuracy: 68.4%\n"
     ]
    }
   ],
   "source": [
    "print(similarity_score_accuracy(classes, V_matrix, T_matrix), \"\\n\")\n",
    "print(max_score_accuracy(classes, V_matrix, T_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cec234f9-52f7-43bb-a8e9-1dfb219d1991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score accuarcy: 65.6 \n",
      "\n",
      "Max Score accuracy: 63.2%\n"
     ]
    }
   ],
   "source": [
    "def get_dot_prods_matrix_test(image_features: torch.Tensor, text_features: torch.Tensor):\n",
    "    image_features = image_features.squeeze(dim=1)\n",
    "    text_features = text_features.squeeze(dim=1)\n",
    "    image_norms = image_features.norm(dim=-1, keepdim=True) ** 2\n",
    "    text_norms = text_features.norm(dim=-1, keepdim=True) ** 2\n",
    "    matrix = image_features @ text_features.T\n",
    "    matrix /= torch.sqrt(image_norms @ text_norms.T)\n",
    "    return matrix\n",
    "\n",
    "V_matrix_non_norm = get_dot_prods_matrix_test(image_features, concept_features)\n",
    "T_matrix_non_norm = get_dot_prods_matrix_test(class_features, concept_features)\n",
    "\n",
    "v_col_sum = torch.sum(V_matrix_non_norm, dim=0, keepdim=True)\n",
    "t_col_sum = torch.sum(T_matrix_non_norm, dim=0, keepdim=True)\n",
    "\n",
    "V_matrix_norm_col = V_matrix_non_norm / v_col_sum\n",
    "T_matrix_norm_col = T_matrix_non_norm / t_col_sum\n",
    "\n",
    "print(similarity_score_accuracy(classes, V_matrix_norm_col, T_matrix_norm_col), \"\\n\")\n",
    "print(max_score_accuracy(classes, V_matrix_norm_col, T_matrix_norm_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e2c99-05ca-49ce-9036-e4cdf57c25b9",
   "metadata": {},
   "source": [
    "max score accuracy is better when we normalize by rows while the similarity accuracy better when we normalize by rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b080a678-6237-410e-8d4d-8350461af49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score accuracy for the class airplane 80.0%\n",
      "Similarity Score accuracy for the class automobile 0.0%\n",
      "Similarity Score accuracy for the class bird 88.0%\n",
      "Similarity Score accuracy for the class cat 0.0%\n",
      "Similarity Score accuracy for the class deer 92.0%\n",
      "Similarity Score accuracy for the class dog 0.0%\n",
      "Similarity Score accuracy for the class frog 72.0%\n",
      "Similarity Score accuracy for the class horse 92.0%\n",
      "Similarity Score accuracy for the class ship 86.0%\n",
      "Similarity Score accuracy for the class truck 100.0%\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes.values():\n",
    "    print(\"Similarity Score accuracy for the class {}\".format(class_name), \n",
    "          \"{}%\".format(calculate_similarity_score_accuracy_for_class(class_name, V_matrix, T_matrix, classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8f31f08b-c8bf-46be-9b29-07041946be88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score accuracy for the class airplane 66.0%\n",
      "Similarity Score accuracy for the class automobile 20.0%\n",
      "Similarity Score accuracy for the class bird 80.0%\n",
      "Similarity Score accuracy for the class cat 24.0%\n",
      "Similarity Score accuracy for the class deer 86.0%\n",
      "Similarity Score accuracy for the class dog 26.0%\n",
      "Similarity Score accuracy for the class frog 76.0%\n",
      "Similarity Score accuracy for the class horse 98.0%\n",
      "Similarity Score accuracy for the class ship 92.0%\n",
      "Similarity Score accuracy for the class truck 88.0%\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes.values():\n",
    "    print(\"Similarity Score accuracy for the class {}\".format(class_name), \n",
    "          \"{}%\".format(calculate_similarity_score_accuracy_for_class(class_name, V_matrix_norm_col, T_matrix_norm_col, classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7741928c-6d6a-4a91-8d69-e4dd6274ea06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Score accuracy for the class airplane 72.0%\n",
      "Max Score accuracy for the class automobile 78.0%\n",
      "Max Score accuracy for the class bird 78.0%\n",
      "Max Score accuracy for the class cat 54.0%\n",
      "Max Score accuracy for the class deer 84.0%\n",
      "Max Score accuracy for the class dog 58.0%\n",
      "Max Score accuracy for the class frog 50.0%\n",
      "Max Score accuracy for the class horse 82.0%\n",
      "Max Score accuracy for the class ship 66.0%\n",
      "Max Score accuracy for the class truck 62.0%\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes.values():\n",
    "    print(\"Max Score accuracy for the class {}\".format(class_name), \n",
    "          \"{}%\".format(calculate_max_score_accuracy_for_class(class_name, V_matrix, T_matrix, classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "59099238-e3b4-4dc9-a299-9a9209a198d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Score accuracy for the class airplane 36.0%\n",
      "Max Score accuracy for the class automobile 32.0%\n",
      "Max Score accuracy for the class bird 74.0%\n",
      "Max Score accuracy for the class cat 64.0%\n",
      "Max Score accuracy for the class deer 38.0%\n",
      "Max Score accuracy for the class dog 74.0%\n",
      "Max Score accuracy for the class frog 70.0%\n",
      "Max Score accuracy for the class horse 92.0%\n",
      "Max Score accuracy for the class ship 80.0%\n",
      "Max Score accuracy for the class truck 72.0%\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes.values():\n",
    "    print(\"Max Score accuracy for the class {}\".format(class_name), \n",
    "          \"{}%\".format(calculate_max_score_accuracy_for_class(class_name, V_matrix_norm_col, T_matrix_norm_col, classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c5974-8db7-4a6d-b929-efa768a1df27",
   "metadata": {
    "tags": []
   },
   "source": [
    "# json llama concetpts tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "667fdbe0-248c-4ee9-9db1-84e1543d6559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"concepts_llama_mixed_prompts_chunck2.json\", \"r\") as fp:\n",
    "    llama_concepts_raw = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a50bc5e1-da88-4d32-9b46-91df6eac7046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "llama_concepts = []\n",
    "\n",
    "for key, value in llama_concepts_raw.items():\n",
    "    if \"A1\" in value:\n",
    "        a1_text = value[\"A1\"]\n",
    "        lines = a1_text.split(\"\\n\")\n",
    "        lines.pop(0)\n",
    "        lines = [element for element in lines if element != '']\n",
    "        lines = [element for element in lines if not element.strip().replace(\".\", \"\").isdigit()]\n",
    "        lines = [re.sub(r'[0-9.]', '', line) for line in lines]\n",
    "        lines = [re.sub(r'[*|-\\–_+()]', '', line) for line in lines]\n",
    "        lines = [re.sub(r'[---]', '', line) for line in lines]\n",
    "        lines = [re.sub(r'[A-J\\t]', '', line) for line in lines]\n",
    "        lines = [re.sub(r'[#]', '', line) for line in lines]\n",
    "        lines = [element for element in lines if element != '']\n",
    "        lines = [line.lstrip() for line in lines]\n",
    "        for line in lines:\n",
    "            if len(line) <= 25:\n",
    "                llama_concepts.append(line)\n",
    "                    \n",
    "    if \"A2\" in value:\n",
    "        a2_text = value[\"A2\"]\n",
    "        lines = a2_text.split('\\n')\n",
    "        lines.pop(0)\n",
    "        lines = [element for element in lines if element != '']\n",
    "        lines = [element for element in lines if not element.strip().replace(\".\", \"\").isdigit()]\n",
    "        lines = [re.sub(r'[0-9.]', '', line) for line in lines]\n",
    "        lines = [re.sub(r'[*|-\\–_+()]', '', line) for line in lines]\n",
    "        lines = [re.sub(r'[---]', '', line) for line in lines]\n",
    "        lines = [re.sub(r'[A-J\\t]', '', line) for line in lines]\n",
    "        lines = [re.sub(r'[#]', '', line) for line in lines]\n",
    "        lines = [element for element in lines if element != '']\n",
    "        lines = [line.lstrip() for line in lines]\n",
    "        for line in lines:\n",
    "            if len(line) <= 25:\n",
    "                llama_concepts.append(line)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2d8dbd6e-f858-48d9-bcd7-c58415052110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"llama_concepts_test.txt\", \"w\") as f:\n",
    "    for i, item in enumerate(llama_concepts):\n",
    "        if i < len(llama_concepts) - 1:\n",
    "            f.write(item.lower() + \"\\n\")\n",
    "        else: f.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ef96ed45-36db-4613-9e59-b9fa83fc1fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1196/1196 [00:09<00:00, 127.80it/s]\n"
     ]
    }
   ],
   "source": [
    "llama_concept_features = get_text_features(\"llama_concepts_test.txt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b710836a-2ea7-4a12-aee5-b92fd2e5d9f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_matrix: torch.Size([500, 1196]) \n",
      "\n",
      "T_matrix: torch.Size([10, 1196])\n"
     ]
    }
   ],
   "source": [
    "V_matrix_llama = get_dot_prods_matrix(image_features, llama_concept_features)\n",
    "T_matrix_llama = get_dot_prods_matrix(class_features, llama_concept_features)\n",
    "\n",
    "print('V_matrix:', V_matrix_llama.shape, \"\\n\")\n",
    "print('T_matrix:', T_matrix_llama.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e5a68b27-4970-42ef-85a0-18880cef943f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score accuarcy: 57.6 \n",
      "\n",
      "Max Score accuracy: 55.6%\n"
     ]
    }
   ],
   "source": [
    "print(similarity_score_accuracy(classes, V_matrix_llama, T_matrix_llama), \"\\n\")\n",
    "print(max_score_accuracy(classes, V_matrix_llama, T_matrix_llama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1cec95e6-8bcb-45bb-8608-ea5687c2b076",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score accuarcy: 69.0 \n",
      "\n",
      "Max Score accuracy: 59.4%\n"
     ]
    }
   ],
   "source": [
    "V_matrix_llama_non_norm = get_dot_prods_matrix_test(image_features, llama_concept_features)\n",
    "T_matrix_llama_non_norm = get_dot_prods_matrix_test(class_features, llama_concept_features)\n",
    "\n",
    "v_col_sum = torch.sum(V_matrix_llama_non_norm, dim=0, keepdim=True)\n",
    "t_col_sum = torch.sum(T_matrix_llama_non_norm, dim=0, keepdim=True)\n",
    "\n",
    "V_matrix_llama_norm_col = V_matrix_llama_non_norm / v_col_sum\n",
    "T_matrix_llama_norm_col = T_matrix_llama_non_norm / t_col_sum\n",
    "\n",
    "print(similarity_score_accuracy(classes, V_matrix_llama_norm_col, T_matrix_llama_norm_col), \"\\n\")\n",
    "print(max_score_accuracy(classes, V_matrix_llama_norm_col, T_matrix_llama_norm_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3bf935b5-1c96-4ea4-81bb-a0653a8e2d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Score accuracy for the class airplane 84.0%\n",
      "Max Score accuracy for the class automobile 90.0%\n",
      "Max Score accuracy for the class bird 76.0%\n",
      "Max Score accuracy for the class cat 10.0%\n",
      "Max Score accuracy for the class deer 48.0%\n",
      "Max Score accuracy for the class dog 12.0%\n",
      "Max Score accuracy for the class frog 58.0%\n",
      "Max Score accuracy for the class horse 58.0%\n",
      "Max Score accuracy for the class ship 40.0%\n",
      "Max Score accuracy for the class truck 80.0%\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes.values():\n",
    "    print(\"Max Score accuracy for the class {}\".format(class_name), \n",
    "          \"{}%\".format(calculate_max_score_accuracy_for_class(class_name, V_matrix_llama, T_matrix_llama, classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "810c84a9-85f9-4d76-820d-a51fb2434a69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Score accuracy for the class airplane 0.0%\n",
      "Max Score accuracy for the class automobile 54.0%\n",
      "Max Score accuracy for the class bird 92.0%\n",
      "Max Score accuracy for the class cat 12.0%\n",
      "Max Score accuracy for the class deer 56.0%\n",
      "Max Score accuracy for the class dog 58.0%\n",
      "Max Score accuracy for the class frog 88.0%\n",
      "Max Score accuracy for the class horse 88.0%\n",
      "Max Score accuracy for the class ship 76.0%\n",
      "Max Score accuracy for the class truck 70.0%\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes.values():\n",
    "    print(\"Max Score accuracy for the class {}\".format(class_name), \n",
    "          \"{}%\".format(calculate_max_score_accuracy_for_class(class_name, V_matrix_llama_norm_col, T_matrix_llama_norm_col, classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1f3379-0c75-43a0-8a9a-e6278de72959",
   "metadata": {},
   "source": [
    "# another set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60410677-03b6-4968-82f8-9c7fc8a282f8",
   "metadata": {},
   "source": [
    "https://relatedwords.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d8ec4d49-49d8-4c59-b633-63bfa4fe8cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_concepts = ['plane', 'airliner', 'propeller', 'monoplane', 'fuselage', 'jet', 'car', 'vehicle', 'passenger', 'internal combustion engine', 'minivan', 'sedan',\n",
    "                  'parrot', 'wing', 'passerine', 'fowl', 'albatross', 'geese', 'kiwi', 'syrinx', 'gull', 'lion', 'tiger', 'leopard', 'pet', 'jaguar', 'felis', 'rat', 'rabbit',\n",
    "                  'elk', 'moose', 'reindeer', 'antelope', 'ruminant', 'antler', 'pig', 'sheep', 'alps', 'eurasian elk', 'foxes', 'puppy', 'cur', 'wolf', 'tail', 'great dane', 'poodle', 'hound',\n",
    "                  'canid', 'corgi', 'pawl', 'toad', 'amphibian', 'egg', 'gill', 'lizard', 'tongue', 'carnivore', 'pony', 'foal', 'thoroughbred', 'hack', 'cartilage', 'donkey', 'bridle', 'boat',\n",
    "                  'ferry', 'submarine', 'vessel', 'cargo', 'sail', 'sea', 'barque', 'schooner', 'travel', 'galley', 'water', 'watercraft', 'lorry', 'van', 'wagon', 'suv', 'jeep', 'forklift', \n",
    "                  'bumper', 'trailer', 'driver', 'boxcar', 'flatcar', 'motorbikr', 'oldsmobile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e52b223d-99f8-4309-b5d8-96f17b3da3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"custom_concepts_test.txt\", \"w\") as f:\n",
    "    for item in custom_concepts:\n",
    "        f.write(item + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8bc09f2e-5252-4975-a2a3-c851de148123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 149,620,737\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    }
   ],
   "source": [
    "import open_clip\n",
    "import clip\n",
    "from open_clip import tokenizer\n",
    "\n",
    "clip_model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-16', pretrained='openai', device=device)\n",
    "\n",
    "clip_model.eval()\n",
    "context_length = clip_model.context_length\n",
    "vocab_size = clip_model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in clip_model.parameters()]):,}\")\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d1dc30a9-14e7-4251-964b-30fc6c8492d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 90/90 [00:00<00:00, 123.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_matrix: torch.Size([500, 90]) \n",
      "\n",
      "T_matrix: torch.Size([10, 90])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#custom_concepts_features = get_text_features(\"custom_concepts_test.txt\", device=device)\n",
    "text_encodings = []\n",
    "with torch.no_grad():\n",
    "        for c in tqdm(custom_concepts):\n",
    "            text_input = clip.tokenize(c).to(device)\n",
    "            text_feature = clip_model.encode_text(text_input)\n",
    "            text_encodings.append(text_feature)\n",
    "\n",
    "custom_concepts_features = torch.stack(text_encodings, dim=0)\n",
    "\n",
    "V_matrix_custom = get_dot_prods_matrix(image_features, custom_concepts_features)\n",
    "T_matrix_custom = get_dot_prods_matrix(class_features, custom_concepts_features)\n",
    "\n",
    "print('V_matrix:', V_matrix_custom.shape, \"\\n\")\n",
    "print('T_matrix:', T_matrix_custom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1929f98d-84dc-40cd-80ea-b68afb6b8b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score accuracy: 67.4% \n",
      "\n",
      "Max Score accuracy: 68.2%\n"
     ]
    }
   ],
   "source": [
    "print(similarity_score_accuracy(classes, V_matrix_custom, T_matrix_custom), \"\\n\")\n",
    "print(max_score_accuracy(classes, V_matrix_custom, T_matrix_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "be67db48-55c8-412e-9ddf-0b91e8191d87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score accuarcy: 85.0 \n",
      "\n",
      "Max Score accuracy: 73.8%\n"
     ]
    }
   ],
   "source": [
    "V_matrix_custom_non_norm = get_dot_prods_matrix_test(image_features, custom_concepts_features)\n",
    "T_matrix_custom_non_norm = get_dot_prods_matrix_test(class_features, custom_concepts_features)\n",
    "\n",
    "v_col_sum = torch.sum(V_matrix_custom_non_norm, dim=0, keepdim=True)\n",
    "t_col_sum = torch.sum(T_matrix_custom_non_norm, dim=0, keepdim=True)\n",
    "\n",
    "V_matrix_custom_norm_col = V_matrix_custom_non_norm / v_col_sum\n",
    "T_matrix_custom_norm_col = T_matrix_custom_non_norm / t_col_sum\n",
    "\n",
    "print(similarity_score_accuracy(classes, V_matrix_custom_norm_col, T_matrix_custom_norm_col), \"\\n\")\n",
    "print(max_score_accuracy(classes, V_matrix_custom_norm_col, T_matrix_custom_norm_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8b38c01c-cf7a-4f07-b7e4-99c1746e52af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Score accuracy for the class airplane 92.0%\n",
      "Max Score accuracy for the class automobile 90.0%\n",
      "Max Score accuracy for the class bird 70.0%\n",
      "Max Score accuracy for the class cat 6.0%\n",
      "Max Score accuracy for the class deer 92.0%\n",
      "Max Score accuracy for the class dog 22.0%\n",
      "Max Score accuracy for the class frog 48.0%\n",
      "Max Score accuracy for the class horse 82.0%\n",
      "Max Score accuracy for the class ship 92.0%\n",
      "Max Score accuracy for the class truck 88.0%\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes.values():\n",
    "    print(\"Max Score accuracy for the class {}\".format(class_name), \n",
    "          \"{}%\".format(calculate_max_score_accuracy_for_class(class_name, V_matrix_custom, T_matrix_custom, classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1c5baa6f-5bea-404b-958b-d2bb25d3259c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Score accuracy for the class airplane 86.0%\n",
      "Max Score accuracy for the class automobile 88.0%\n",
      "Max Score accuracy for the class bird 84.0%\n",
      "Max Score accuracy for the class cat 20.0%\n",
      "Max Score accuracy for the class deer 86.0%\n",
      "Max Score accuracy for the class dog 58.0%\n",
      "Max Score accuracy for the class frog 58.0%\n",
      "Max Score accuracy for the class horse 92.0%\n",
      "Max Score accuracy for the class ship 68.0%\n",
      "Max Score accuracy for the class truck 98.0%\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes.values():\n",
    "    print(\"Max Score accuracy for the class {}\".format(class_name), \n",
    "          \"{}%\".format(calculate_max_score_accuracy_for_class(class_name, V_matrix_custom_norm_col, T_matrix_custom_norm_col, classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dae04d-e9f2-414f-bb6c-801c6cdfae38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andronserv",
   "language": "python",
   "name": "andronserv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
